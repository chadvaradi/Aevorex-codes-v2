import re
from pathlib import Path
from collections import defaultdict

# --- Constants ---
WORKSPACE_ROOT = Path(__file__).parent.parent
BACKEND_ROUTES_FILE = WORKSPACE_ROOT / "audits" / "backend_routes_A1_final.txt"
FRONTEND_CALLS_FILE = WORKSPACE_ROOT / "audits" / "frontend_calls_A1_final.txt"
OUTPUT_FILE = WORKSPACE_ROOT / "docs" / "ENDPOINT_MATRIX_v23.md"

# --- Regex Patterns ---
BACKEND_ENDPOINT_REGEX = re.compile(r'(@router\.(get|post|put|delete|patch))\s*\(\s*f?["\'](/{1,2}[^"\']*)["\']\)')
FRONTEND_CALL_REGEX = re.compile(r'["\'](/stock|/auth|/macro|/market)[^"\']+\b')

def parse_backend_file():
    endpoints = defaultdict(list)
    with open(BACKEND_ROUTES_FILE, 'r') as f:
        for line in f:
            filepath, _, code = line.partition(':')
            match = BACKEND_ENDPOINT_REGEX.search(code)
            if match:
                method = match.group(2).upper()
                path = match.group(3)
                # Normalize path
                path = path.replace("//", "/")
                endpoints[path].append({"method": method, "file": filepath.strip()})
    return endpoints

def parse_frontend_file():
    calls = set()
    with open(FRONTEND_CALLS_FILE, 'r') as f:
        for line in f:
            match = FRONTEND_CALL_REGEX.search(line)
            if match:
                path = match.group(0).strip('\'"`')
                # Normalize for comparison
                normalized = re.sub(r'\\$\\{ticker\\}', '{ticker}', path)
                calls.add(f"/api/v1{normalized}") # Add prefix for matching
    return calls

def generate_markdown(backend_endpoints, frontend_calls):
    lines = [
        "# FinanceHub – API ⇄ Frontend Endpoint Matrix (v23)",
        f"> Generated by `{Path(__file__).name}` from grep results.",
        "",
        "| Backend Endpoint | Method | Implemented in | Frontend Usage |",
        "|------------------|--------|----------------|----------------|",
    ]

    all_paths = sorted(backend_endpoints.keys())
    used_count = 0
    
    normalized_frontend_calls = {re.sub(r'\\{.*?\\}', '{ticker}', call) for call in frontend_calls}
    
    for path in all_paths:
        normalized_backend_path = re.sub(r'\\{.*?\\}', '{ticker}', path)
        
        usage_status = "⚠️ NOT USED"
        if normalized_backend_path in normalized_frontend_calls:
            usage_status = "✅ USED"
            used_count += 1
            
        for endpoint in backend_endpoints[path]:
            lines.append(f"| `{path}` | {endpoint['method']} | `{endpoint['file']}` | {usage_status} |")

    total_count = len(all_paths)
    coverage = (used_count / total_count * 100) if total_count > 0 else 0

    lines.extend([
        "\n---",
        "## Summary",
        f"- **Total Backend Endpoints:** {total_count}",
        f"- **Endpoints Used by Frontend:** {used_count}",
        f"- **Coverage:** {coverage:.1f}%",
    ])

    return "\n".join(lines)


def main():
    backend_endpoints = parse_backend_file()
    frontend_calls = parse_frontend_file()
    
    markdown = generate_markdown(backend_endpoints, frontend_calls)
    
    with open(OUTPUT_FILE, 'w') as f:
        f.write(markdown)
        
    print(f"✅ Endpoint matrix generated at {OUTPUT_FILE}")

if __name__ == "__main__":
    main() 